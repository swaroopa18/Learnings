# ğŸ“˜ RAG (Retrieval Augmented Generation) â€” Session Notes

---

## Table of Contents

1. [What is an LLM?](#1-what-is-an-llm)
2. [Limitations of LLMs](#2-limitations-of-llms)
3. [The Smart Intern Analogy](#3-the-smart-intern-analogy)
4. [What is RAG?](#4-what-is-rag)
5. [The Chef Analogy](#5-the-chef-analogy)
6. [RAG Pipeline â€” Data Preparation](#6-rag-pipeline--data-preparation)
7. [RAG Pipeline â€” Retrieval & Generation](#7-rag-pipeline--retrieval--generation)
8. [RAG Paradigms](#8-rag-paradigms)
9. [RAG Architecture (In-Depth)](#9-rag-architecture-in-depth)
10. [Demo Walkthrough](#10-demo-walkthrough)
11. [How to Improve RAG](#11-how-to-improve-rag)
12. [Challenges in RAG](#12-challenges-in-rag)
13. [Key Takeaways](#13-key-takeaways)
14. [References](#14-references)

---

## 1. What is an LLM?

A **Large Language Model (LLM)** is a deep learning model based on the **Transformer architecture**, trained on vast amounts of data (billions of parameters). Its core ability is **next-token prediction** â€” given some text, it predicts what comes next.

> **Example:** You type _"The capital of India is"_ â†’ the LLM completes it with _"New Delhi."_

Other related terms you may hear:

- **SLM** â€” Small Language Model
- **MLM** â€” Medium Language Model

**Primary use cases:** sentence completion, question answering, translation, summarisation, analysis.

---

## 2. Limitations of LLMs

| Limitation                    | Explanation                                                                                                      |
| ----------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| **Hallucination**             | The model can confidently generate wrong or fabricated answers, especially for topics outside its training data. |
| **Outdated Knowledge**        | Training data has a cutoff date; the model doesn't know anything after that.                                     |
| **No Access to Private Data** | LLMs can't access your company's internal or proprietary documents unless you provide them.                      |
| **Overconfidence**            | LLMs always sound confident â€” even when they are completely wrong.                                               |

---

## 3. The Smart Intern Analogy

This is a handy mental model for understanding why LLMs fall short on their own:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THE SMART INTERN                    â”‚
â”‚                                                 â”‚
â”‚  âœ… Speaks extremely well                       â”‚
â”‚  âœ… Has broad general knowledge                 â”‚
â”‚  âŒ Has NO access to company internal files     â”‚
â”‚  âŒ Will GUESS answers with 100% confidence     â”‚
â”‚                                                 â”‚
â”‚  Asked: "What is the leave policy?"             â”‚
â”‚  Intern: "Typically companies give 15 daysâ€¦"   â”‚
â”‚          (sounds confident â€” but may be WRONG) â”‚
â”‚                                                 â”‚
â”‚  ğŸ’¡ Confidence â‰  Correctness                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is exactly how an LLM behaves â€” **confident but potentially incorrect** when it doesn't have the right context.

---

## 4. What is RAG?

**RAG = Retrieval Augmented Generation**

Instead of making the LLM guess, you **give it the data to look up** before generating an answer.

### High-Level RAG Flow

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  User asks a           â”‚              â”‚
  question â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚   Knowledge  â”‚
                        â”‚     Base     â”‚
                        â”‚  (Docs/DB)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    Relevant chunks retrieved
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   Question â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚     LLM      â”‚ â”€â”€â”€â”€â”€â”€â–º Answer
                        â”‚  (Generator) â”‚          to User
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**In plain words:**

1. The user's question goes to a **knowledge base**.
2. Relevant information (chunks) is **retrieved**.
3. The retrieved context + the original question are sent to the **LLM**.
4. The LLM generates an answer **grounded in actual data**.

---

## 5. The Chef Analogy

A great way to remember how each piece of RAG works:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ³ THE CHEF ANALOGY                  â”‚
â”‚                                                        â”‚
â”‚  ğŸ“– Recipe Book          â†’  Knowledge Base             â”‚
â”‚  ğŸ” Finding the recipe   â†’  Vector Retrieval           â”‚
â”‚  ğŸ“ The recipe steps     â†’  Retrieved Chunk            â”‚
â”‚  ğŸ‘¨â€ğŸ³ Cooking               â†’  LLM Generation           â”‚
â”‚  ğŸ½ï¸  Dish quality          â†’  Answer Accuracy           â”‚
â”‚                                                        â”‚
â”‚  The chef doesn't cook from memory â€” he LOOKS IT UP   â”‚
â”‚  in the book first. That's exactly what RAG does.      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. RAG Pipeline â€” Data Preparation

Data preparation is the **foundation** of a good RAG system. If the data isn't prepared well, retrieval will suffer.

### Full Data Preparation Flow

![alt text](rag_architecture.png)

### 6a. Chunking

Chunking splits your data into smaller, relevant pieces. Two key parameters:

- **Chunk Size** â€” how many characters/tokens in one chunk (e.g., 500â€“2000 characters)
- **Overlap** â€” how many characters are shared between consecutive chunks

```
  Chunk 1: [=============================]
  Chunk 2:                    [=============================]
                              ^^^^^^^^
                              Overlap (e.g., 50â€“200 chars)
```

**Why overlap matters:** If Chunk 2 refers back to something in Chunk 1 (e.g., a pronoun like "he" referring to a name in Chunk 1), the overlap ensures that connection isn't lost during retrieval.

**Chunking strategies:**

1. **Fixed-size chunking** â€” split every N characters (simplest)
2. **Delimiter-based chunking** â€” split on paragraphs, sentences, or punctuation
3. **Semantic/intelligent chunking** â€” use a model to decide where meaningful boundaries are

### 6b. Embedding

Embedding converts text chunks into **vectors** â€” numerical coordinates in a high-dimensional space.

```
  "India"    â†’  [0.12, 0.45, 0.78, â€¦]   â— India
  "Delhi"    â†’  [0.14, 0.47, 0.80, â€¦]     â— Delhi   (close to India)
  "Paris"    â†’  [0.91, 0.22, 0.11, â€¦]
                                            â— Paris   (far from India)

  Similar meanings = closer vectors in space
```

Embeddings also include **positional encoding** â€” so the model knows the _order_ of words in a sentence.

### 6c. Why a Vector Database?

A regular SQL/NoSQL database stores data for _humans_ to query. A **vector database** stores data in a way that makes **similarity search** fast and efficient for machines.

---

## 7. RAG Pipeline â€” Retrieval & Generation

Once data is stored, here's what happens at **query time**:

```
  User Query
      â”‚
      â–¼
  Embed the Query  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  (convert to vector)                â”‚
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  VECTOR DB      â”‚
                            â”‚  Similarity     â”‚
                            â”‚  Search (Top-K) â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                         Retrieved Chunks
                                     â”‚
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Original Query â”€â”€â”€â”€â”€â”€â–º    â”‚      LLM        â”‚  â”€â”€â–º  Final Answer
                            â”‚   (Generation)  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key terms:**

- **Top-K** â€” how many of the most similar chunks to retrieve (e.g., K=2, K=5, K=7)
- **Cosine Similarity** â€” the standard method to measure how close two vectors are

---

## 8. RAG Paradigms

There are several patterns/approaches for building RAG systems:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG PARADIGMS                            â”‚
â”‚                                                             â”‚
â”‚  â‘  NAIVE / STANDARD RAG                                     â”‚
â”‚     Query â†’ Retrieve â†’ Generate                             â”‚
â”‚     Simple, fast, good for basic FAQ / narrow use cases     â”‚
â”‚                                                             â”‚
â”‚  â‘¡ ADVANCED RAG                                             â”‚
â”‚     Adds layers BEFORE and AFTER retrieval:                 â”‚
â”‚     â€¢ Query Rewriting / Expansion (before)                  â”‚
â”‚     â€¢ Filtering                                             â”‚
â”‚     â€¢ Re-ranking                                            â”‚
â”‚     â€¢ Fusion (combine results from multiple sources)        â”‚
â”‚     Better accuracy, handles vague queries                  â”‚
â”‚                                                             â”‚
â”‚  â‘¢ MODULAR RAG                                              â”‚
â”‚     Plug-and-play â€” only activate modules when needed       â”‚
â”‚     â€¢ Router-based: directs queries to right model/DB       â”‚
â”‚     â€¢ Graph RAG: builds knowledge graphs for relationships  â”‚
â”‚     â€¢ Agentic RAG: the RAG can take actions autonomously    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Advanced RAG â€” Detailed Flow

```
  User Query
      â”‚
      â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Query Expansion  â”‚  â† Use another model to rewrite/expand
  â”‚  / Rewriting     â”‚     the query with better keywords
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Retrieval      â”‚  â† Fetch more relevant chunks
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Filtering      â”‚  â† Remove irrelevant results
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Re-ranking     â”‚  â† Reorder by relevance using a model
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  LLM Generation  â”‚  â† Generate grounded answer
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Graph RAG

When documents have lots of **relationships**, a graph structure is better than plain vector search.

```
  Documents â”€â”€â–º Extract Entities & Relations â”€â”€â–º Graph DB (e.g., Neo4j)
                                                      â”‚
                                                      â–¼
                                              Query retrieves
                                              not just facts,
                                              but RELATIONSHIPS too
```

> âš ï¸ Trade-off: Graph generation adds cost and complexity.

### Agentic RAG

RAG that can **take actions** â€” not just answer questions, but execute tools, run code, or make decisions on its own.

---

## 9. RAG Architecture (In-Depth)

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                   COMPLETE RAG ARCHITECTURE                  â”‚
  â”‚                                                             â”‚
  â”‚  [Documents]                                                â”‚
  â”‚       â”‚                                                     â”‚
  â”‚       â–¼                                                     â”‚
  â”‚  [Embedding Model]  â”€â”€â–º  [Vector Database]                  â”‚
  â”‚                               â”‚                             â”‚
  â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                             â”‚
  â”‚                    â”‚          â”‚                             â”‚
  â”‚             Sparse â”‚    Dense â”‚  â† Hybrid Retrieval         â”‚
  â”‚           (keyword)â”‚ (vector) â”‚                             â”‚
  â”‚                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                             â”‚
  â”‚                         â–¼                                   â”‚
  â”‚                   [Re-Ranker]   â† Optional                  â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚              [Retrieved Context]                             â”‚
  â”‚                    +                                        â”‚
  â”‚              [User Query/Prompt]                             â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚                  [LLM / Generator]                           â”‚
  â”‚                         â”‚                                   â”‚
  â”‚                         â–¼                                   â”‚
  â”‚               [Formatted Response]  â”€â”€â–º  User               â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Retrieval Types

| Type       | Method                  | Example                |
| ---------- | ----------------------- | ---------------------- |
| **Sparse** | Keyword matching        | Elasticsearch, BM25    |
| **Dense**  | Vector similarity       | Embedding-based search |
| **Hybrid** | Combines Sparse + Dense | Best of both worlds    |

> ğŸ’¡ **Hybrid retrieval** is currently the most popular approach because neither keyword search nor vector search alone is perfect.

---

## 10. Demo Walkthrough

### Tools & Stack Used

| Component           | Tool / Library                           | Purpose                         |
| ------------------- | ---------------------------------------- | ------------------------------- |
| Framework           | **LangChain**                            | Building the LLM app pipeline   |
| Expression Language | **LCEL** (LangChain Expression Language) | Chaining steps with pipe syntax |
| Embedding Model     | **all-MiniLM** (Hugging Face)            | Converting text to vectors      |
| LLM                 | **Gemma 2 (2B params)** via Ollama       | Generating answers              |
| Vector DB           | **Qdrant**                               | Storing & searching vectors     |
| Orchestration       | **LangGraph**                            | Managing multi-step workflows   |

### Demo Structure

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚           DEMO FLOW                            â”‚
  â”‚                                                â”‚
  â”‚  1. Raw text data (fictional restaurant info)  â”‚
  â”‚         â”‚                                      â”‚
  â”‚         â–¼                                      â”‚
  â”‚  2. Chunking (size=500, overlap=50)            â”‚
  â”‚         â”‚                                      â”‚
  â”‚         â–¼                                      â”‚
  â”‚  3. Embed â†’ Store in Qdrant                    â”‚
  â”‚         â”‚                                      â”‚
  â”‚         â–¼                                      â”‚
  â”‚  4a. NAIVE RAG  â†’  Direct query â†’ LLM         â”‚
  â”‚  4b. ADVANCED RAG â†’ Enhance query â†’            â”‚
  â”‚       Retrieve more â†’ Refine if uncertain â†’    â”‚
  â”‚       Generate better answer                   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Observations from Demo

- **Without RAG:** The LLM said _"I don't have access to real-time information"_ and gave generic advice.
- **With Naive RAG (K=2):** Answered simple questions correctly but struggled with complex, multi-part queries.
- **With Advanced RAG (K=7 + query enhancement + refinement loop):** Provided more detailed, accurate answers. Also broke down complex questions automatically.

### LangGraph State Machine Concept

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Enhance  â”‚â”€â”€â”€â–ºâ”‚ Retrieve  â”‚â”€â”€â”€â–ºâ”‚  Generate  â”‚
  â”‚  Query   â”‚    â”‚  Docs     â”‚    â”‚  Answer    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                          Uncertain?     â”‚  Confident?
                             â–¼           â”‚      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚    [END]
                        â”‚ Refine  â”‚      â”‚
                        â”‚  Query  â”‚      â”‚
                        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â”‚
                             â”‚           â”‚
                             â–¼           â”‚
                        (loop back)      â”‚
                                         â”‚
```

Each node holds its own **state** (current query, retrieved docs, answer, refinement flag). The graph decides which node to visit next based on the state.

---

## 11. How to Improve RAG

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚              IMPROVEMENT STRATEGIES                 â”‚
  â”‚                                                    â”‚
  â”‚  1. HYBRID SEARCH                                  â”‚
  â”‚     Combine keyword (BM25) + vector search         â”‚
  â”‚     â†’ Reduces missed results                       â”‚
  â”‚                                                    â”‚
  â”‚  2. BETTER CHUNKING                                â”‚
  â”‚     Use semantic or hybrid chunking instead of     â”‚
  â”‚     fixed-size                                     â”‚
  â”‚                                                    â”‚
  â”‚  3. RE-RANKING                                     â”‚
  â”‚     After retrieval, use a model to reorder        â”‚
  â”‚     chunks by true relevance                       â”‚
  â”‚                                                    â”‚
  â”‚  4. QUERY DECOMPOSITION                            â”‚
  â”‚     Break complex queries into sub-queries,        â”‚
  â”‚     answer each, then fuse results                 â”‚
  â”‚     Example: "Compare React vs Android"            â”‚
  â”‚       â†’ Query 1: "Tell me about React"             â”‚
  â”‚       â†’ Query 2: "Tell me about Android"           â”‚
  â”‚       â†’ Fuse & compare                             â”‚
  â”‚                                                    â”‚
  â”‚  5. CONVERSATION MEMORY                            â”‚
  â”‚     â€¢ Short-term: current session context          â”‚
  â”‚     â€¢ Long-term: user persona across sessions      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 12. Challenges in RAG

### 12a. Low-Quality Retrieval

- Use **hybrid retrieval** (sparse + dense)
- Add a **re-ranking layer**
- Continuously **monitor precision** and iterate

### 12b. Context Window Limitation

```
  Retrieved Chunks: [C1] [C2] [C3] [C4] [C5] [C6] [C7] â€¦
                    |___________________________________|
                              Context Window
                           (has a MAX limit!)

  If exceeded â†’ information gets lost or ignored

  Solutions:
    â€¢ Filter out less relevant chunks
    â€¢ Summarise chunks before passing to LLM
    â€¢ Use document compression
```

### 12c. Latency & Cost

- **Cache** frequently asked queries and their embeddings
- Use **smaller models** for intermediate steps (e.g., query rewriting) and larger ones only for final generation
- Choose **optimised vector stores** for your data source

### 12d. Security & Governance

- Prevent sensitive data from leaking to external models
- Enforce **access control** and **multi-tenancy** in your vector DB
- Maintain proper **audit logs**

### 12e. Evaluation (The Hardest Part)

- Prepare a **sample set** of documents + expected Q&A pairs
- Use **human-in-the-loop scoring** for quality checks
- Use tools like **TruLens** or **RAGAS** for automated factuality checks
- Collect **user feedback** (thumbs up/down) to improve over time

---

## 13. Key Takeaways

| #   | Takeaway                                               | Why It Matters                                                       |
| --- | ------------------------------------------------------ | -------------------------------------------------------------------- |
| 1   | **RAG is a system design pattern**                     | It's flexible â€” you can plug/swap components as needed               |
| 2   | **Models don't have to be huge**                       | RAG accuracy depends more on **retrieval quality** than model size   |
| 3   | **Open-source models are production-viable**           | With good retrieval + ingestion, smaller open models work well       |
| 4   | **Start simple, iterate often**                        | Begin with naive RAG, then add modules one by one                    |
| 5   | **LLM alone = guessing; LLM + RAG = grounded answers** | RAG is what makes LLMs actually useful for specific, real-world data |

---

## 14. References

- **CRAG (Corrective RAG)** â€” Adds a post-generation relevance check using a model before returning the answer. Prevents vague or hallucinated responses from reaching the user.
- **LightRAG** (by Meta) â€” A lighter alternative to Graph RAG that achieves comparable accuracy with less overhead.
- **GraphRAG** (by Microsoft) â€” Uses knowledge graphs to capture and retrieve entity relationships from documents.

---

_Notes compiled from the RAG introductory session. For deeper dives into any section (e.g., vector databases, LangGraph, or advanced retrieval), a separate session is recommended._
